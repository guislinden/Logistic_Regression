#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
rpart.plot(tree_prior)
rpart.plot(tree_min)
#Precisamos dar restart nos datasets
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
#construiremos o modelo de arvore de decisao
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(tree_prior, uniform = T)
# adicionaremos o texto na arvore
text(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
# Create tree_min
<- tree_prior$cptable[index, "CP"]
#  Prune the tree using tree_min
ptree_prior <- prune(tree_prior, cp = tree_min)
# Use prp() to plot the pruned tree
prp(ptree_prior)
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_prior
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
acc_prior
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 0.8)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
# Obtain the actual default status for the accepted loans
accepted_status_prior_80 <-  test_set$loan_status[bin_pred_prior_80 == 0]
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
ROC_prior <- roc(test_set$loan_status, prob_default_prior)
plot(ROC_prior, col="blue")
auc(ROC_prior)
library(rpart.plot)
rpart.plot(tree_min)
rpart.plot(as.rpart(tree_min))
str(tree_min)
str(tree_prior)
tree_min
str(ptree_prior)
rpart.plot(ptree_prior)
training_set
novos_dados <- data.frame(
loan_amnt = 10000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = 8-11 ,
emp_cat = 0-15 )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 10000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior, novos_dados, type = "response")
class
predict(ptree_prior, novos_dados, type = "class")
novos_dados
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 1000000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = as.factor("8-11") ,
emp_cat = as.factor("0-15"))
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior  , newdata = test_set,  type = "class")
answer = predict(ptree_prior, novos_dados, type = "class")
answer = predict(ptree_prior, novos_dados, type = "class"))
answer
answer
answer
answer
novos_dados <- data.frame(loan_status = 1,
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = as.factor("8-11") ,
emp_cat = as.factor("0-15"))
answer = predict(ptree_prior, novos_dados, type = "class")
answer
ir_cat = as.factor(c("8-11")) ,
novos_dados <- data.frame(loan_status = c(1),
loan_amnt = c(100),
grade = c("A") ,
home_ownership = c("RENT") ,
annual_inc = c(1000000),
age = c(30),
ir_cat = as.factor(c("8-11")) ,
emp_cat = as.factor(c("0-15")))
answer = predict(ptree_prior, novos_dados, type = "class")
answer
answer = predict(tree_prior, novos_dados, type = "class")
answer
answer = predict(tree_prior, newdata = novos_dados, type = "class")
answer
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_prior
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(0),
loan_amnt = c(100),
grade = c("A") ,
home_ownership = c("RENT") ,
annual_inc = c(1000000),
age = c(30),
ir_cat = as.factor(c("8-11")) ,
emp_cat = as.factor(c("0-15")))
answer = predict(tree_prior, newdata = novos_dados, type = "class")
table(novos_dados$loan_status, answer)
answer
View(test_set)
novos_dados
colnames(novos_dados)
identical(colnames(novos_dados), colnames(test_set))
colnames(test_set)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
answer = predict(tree_prior, newdata = novos_dados, type = "class")
table(novos_dados$loan_status, answer)
answer
resposta
resposta
resposta = predict(tree_prior, newdata = novos_dados, type = "class")
resposta
table(novos_dados$loan_status, answer)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(predictions_all_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
table(novos_dados$loan_status, resposta)
predict(log_model_full, newdata = novos_dados, type = "response")
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
index
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
tree_prior
tree_prior$cptable
tree_prior$cptable[ , "xerror"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
prune(tree_prior, cp = tree_min)
# E agora vamos ver a nossa arvore usando prp, que faz uma arvore mais bonita
prp(ptree_prior)
confmat_prior
nrow(test_set
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
acc_prior
predict(ptree_prior, newdata = test_set)[ ,2]
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)
predict(ptree_prior, newdata = test_set)
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[,2]
[,2]
predict(ptree_prior, newdata = test_set)[,2]
quantile(prob_default_prior, 0.8)
ifelse(prob_default_prior > cutoff_prior, 1, 0)
test_set$loan_status[bin_pred_prior_80 == 0]
prob_default_prior
quantile(prob_default_prior, 0.8)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 1)
quantile(prob_default_prior, 1)
mean(prob_default_prior)
prob_default_prior
mean(prob_default_prior[1])
prob_default_prior[1]
prob_default_prior[1]
prob_default_prior[1]
mean(prob_default_prior)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 1)
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
prob_default_prior
#Aqui, selecionaremos as probabilidades de default do nosso modelo
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, .2)
cutoff_prior
cutoff_prior
# Vamos transformar o nosso data_set em 1 e 0
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
bin_pred_prior_80
accepted_status_prior_80
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
auc(ROC_modelo)
# Draw all ROCs on one plot
plot(ROC_modelo)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
auc(ROC_modelo)
test_set$loan_status
previsao_modelo_completo
# Daremos restart nos datasets
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
library(pROC)
#construiremos o modelo de arvore de decisao
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(tree_prior, uniform = T)
# adicionaremos o texto na arvore
text(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Vamos verificar para qual CP, a taxa de erro é  minimizada com a seguinte funcao.
printcp(tree_prior)
# Agora, selecionaremos o índice no qual o valor é o menor erro (existem outras maneiras de fazer isso)
index <- which.min(tree_prior$cptable[ , "xerror"])
# Criaremos o valor com o minimo de erro da arvore
tree_min <- tree_prior$cptable[index, "CP"]
#  Usaremos a funcao prune para diminuir a complexidade da arvore
ptree_prior <- prune(tree_prior, cp = tree_min)
prp(ptree_prior)
# E usar ela para prever o nosso test_set
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
prp(ptree_prior)
require(prp)
library(rpart.plot)
prp(ptree_prior)
# E usar ela para prever o nosso test_set
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_prior
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
acc_prior
# Daremos restart nos datasets
library(readr)
test_set <- read_csv("test_set.csv")
source('~/GitHub/Logistic_Regression/arvore_de_decisao.R', echo=TRUE)
# Obtain the bad rate for the accepted loans
sum(aceitos_previsor_80) / length(aceitos_previsor_80)
divisor_aguas <- quantile(prob_default_cortada, .8)
mean(prob_default_cortada)
# Vamos transformar o nosso data_set em 1 e 0
previsor_binario_80 <- ifelse(prob_default_cortada > divisor_aguas, 1, 0)
# Obtain the actual default status for the accepted loans
aceitos_previsor_80 <-  test_set$loan_status[previsor_binario_80 == 0]
# Obtain the bad rate for the accepted loans
sum(aceitos_previsor_80) / length(aceitos_previsor_80)
ROC_arvore_cortada <- roc(test_set$loan_status, prob_default_prior)
ROC_arvore_cortada <- roc(test_set$loan_status, prob_default_cortada)
plot(ROC_arvore_cortada, col="blue")
auc(ROC_arvore_cortada)
previsor_binario_80
test_set$loan_status
aceitos_previsor_80
# Obtain the actual default status for the accepted loans
aceitos_previsor_80 <-  test_set$loan_status[previsor_binario_80 == 0]
aceitos_previsor_80
sum(aceitos_previsor_80)
length(aceitos_previsor_80)
# Obtain the bad rate for the accepted loans
sum(aceitos_previsor_80) / length(aceitos_previsor_80)
# Aqui, compararemos quantos falsos positivos tem no total de positivos
sum(aceitos_previsor_80) / length(aceitos_previsor_80)
matrix_confusao
8315+345
#Aqui, selecionaremos as probabilidades de default do nosso modelo
prob_default_cortada <- predict(arvore_cortada, newdata = test_set)[ ,2]
divisor_aguas <- quantile(prob_default_cortada, .8)
mean(prob_default_cortada)
# Vamos transformar o nosso data_set em 1 e 0
previsor_binario_80 <- ifelse(prob_default_cortada > divisor_aguas, 1, 0)
#Aqui, selecionaremos as probabilidades de default do nosso modelo
prob_default_cortada <- predict(arvore_cortada, newdata = test_set)[ ,2]
divisor_aguas <- quantile(prob_default_cortada, .8)
mean(prob_default_cortada)
# Vamos transformar o nosso data_set em 1 e 0
previsor_binario_80 <- ifelse(prob_default_cortada > divisor_aguas, 1, 0)
# Obteremos o status real para os emprestimos que o modelo disse que foi 0
aceitos_previsor_80 <-  test_set$loan_status[previsor_binario_80 == 0]
# Vamos transformar o nosso data_set em 1 e 0
previsor_binario_80 <- ifelse(prob_default_cortada > divisor_aguas, 1, 0)
# Obteremos o status real para os emprestimos que o modelo disse que foi 0
aceitos_previsor_80 <-  test_set$loan_status[previsor_binario_80 == 0]
# Aqui, compararemos quantos falsos positivos tem no total de positivos
sum(aceitos_previsor_80) / length(aceitos_previsor_80)
sum(aceitos_previsor_80)
length(aceitos_previsor_80)
ROC_arvore_cortada <- roc(test_set$loan_status, prob_default_cortada)
ROC_arvore_cortada <- roc(test_set$loan_status, prob_default_cortada)
plot(ROC_arvore_cortada, col="blue")
auc(ROC_arvore_cortada)
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.3,0.7)),
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(arvore_completa, uniform = T)
# adicionaremos o texto na arvore
text(arvore_completa)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(arvore_completa)
# Vamos verificar para qual CP, a taxa de erro é  minimizada com a seguinte funcao.
printcp(arvore_completa)
# Agora, selecionaremos o índice no qual o valor é o menor erro (existem outras maneiras de fazer isso)
indice <- which.min(arvore_completa$cptable[ , "xerror"])
# Criaremos o valor com o minimo de erro da arvore
minimo_arvore <- arvore_completa$cptable[indice, "CP"]
#  Usaremos a funcao prune para diminuir a complexidade da arvore
arvore_cortada <- prune(arvore_completa, cp = minimo_arvore)
prp(arvore_cortada)
# E usar ela para prever o nosso test_set
previsao_arvore <- predict(arvore_cortada  , newdata = test_set,  type = "class")
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set,
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(arvore_completa, uniform = T)
# adicionaremos o texto na arvore
text(arvore_completa)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(arvore_completa)
# Vamos verificar para qual CP, a taxa de erro é  minimizada com a seguinte funcao.
printcp(arvore_completa)
# Agora, selecionaremos o índice no qual o valor é o menor erro (existem outras maneiras de fazer isso)
indice <- which.min(arvore_completa$cptable[ , "xerror"])
# Criaremos o valor com o minimo de erro da arvore
minimo_arvore <- arvore_completa$cptable[indice, "CP"]
#  Usaremos a funcao prune para diminuir a complexidade da arvore
arvore_cortada <- prune(arvore_completa, cp = minimo_arvore)
prp(arvore_cortada)
# E usar ela para prever o nosso test_set
previsao_arvore <- predict(arvore_cortada  , newdata = test_set,  type = "class")
matrix_confusao <- table(test_set$loan_status, previsao_arvore)
matrix_confusao
precisao <- sum(diag(matrix_confusao)) / nrow(test_set)
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7)),
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(arvore_completa, uniform = T)
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set,
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(arvore_completa, uniform = T)
# adicionaremos o texto na arvore
text(arvore_completa)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(arvore_completa)
# Vamos verificar para qual CP, a taxa de erro é  minimizada com a seguinte funcao.
printcp(arvore_completa)
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.0001))
# plotaremos a arvore
plot(arvore_completa, uniform = T)
# adicionaremos o texto na arvore
text(arvore_completa)
#construiremos o modelo de arvore de decisao
arvore_completa <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
