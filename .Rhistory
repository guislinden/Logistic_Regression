# Compute the median of int_rate
median_ir <- median(loan_data$int_rate, na.rm = T)
# Make copy of loan_data
loan_data_replace <- loan_data
# Replace missing interest rates with median
loan_data_replace$int_rate[na_index] <- median_ir
# Make the necessary replacements in the coarse classification example below
loan_data$ir_cat <- rep(NA, length(loan_data$int_rate))
loan_data$ir_cat[which(loan_data$int_rate <= 8)] <- "0-8"
loan_data$ir_cat[which(loan_data$int_rate > 8 & loan_data$int_rate <= 11)] <- "8-11"
loan_data$ir_cat[which(loan_data$int_rate > 11 & loan_data$int_rate <= 13.5)] <- "11-13.5"
loan_data$ir_cat[which(loan_data$int_rate > 13.5)] <- "13.5+"
loan_data$ir_cat[which(is.na(loan_data$int_rate))] <- "Missing"
loan_data$ir_cat <- as.factor(loan_data$ir_cat)
# Set seed of 567
set.seed(567)
# Store row numbers for training set: index_train
index_train <- sample(1:nrow(loan_data), 2/3 * nrow(loan_data))
# Create training set: training_set
training_set <- loan_data[index_train, ]
# Create test set: test_set
test_set <- loan_data[-index_train, ]
# Construir um modelo de regressÃ£o logÃ­stica com ir_cat como variÃ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Print the parameter estimates
log_model_cat
# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
training_set
View(training_set)
# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
# Print the parameter estimates
log_model_cat
log_model_cat
training_set
args(sample)
?attach
#Bem-vindos ao tutorial de como realizar uma regressÃ£o com R
#A primeira coisa a fazer Ã© adicionar a base de dados que queremos
#Para isso, podemos clicar em "Import Dataset" no quadrante superior a direita
#Nesse caso, adicionamos uma base de dados chamada exemplo_1
#Para falarmos com o R que de agora em diante nos referimos a essa base de dados,
#Utilizamos a funÃ§Ã£o "attach()"
attach(exemplo_1)
#Para visualizar grÃ¡ficamente, usamos a funÃ§Ã£o "plot(x,y)" ou "plot(y~x)"
#"y~x" significa "y em funÃ§Ã£o de x"
plot(experiencia,salario)
#Upload the data to Rstudio
library(readr)
loan_data <- read_csv("C:\\Users\\User\\Documents\\GitHub\\Logistic_Regression\\MyData.csv")
source('~/GitHub/Logistic_Regression/mydata2.R', encoding = 'UTF-8', echo=TRUE)
#QUAL A CHANCE DE DEFAULT PARA ir_cat8-11 ?
ir_cat8-11
# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
# Obtain significance levels using summary()
x = summary(log_model_multi)
x$call
x$terms
x$coefficients
x$coefficients
x$coefficients[3]
x$coefficients[4]
x$coefficients[,2]
x$coefficients[,4]
x$coefficients[,4] < 0.05
# Obtain significance levels using summary()
summary(log_model_multi)
write.csv(training_set, file = "training_set.csv")
write.csv(test_set, file = "test_set.csv")
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
# Construir um modelo de regressÃ£o logÃ­stica com ir_cat como variÃ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Vamos ver os parametros do modelo
log_model_cat
# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
predict(log_model_multi, c(33, "8-11", "B", 10000, 30000), type = "response")
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
predict(log_model_multi, c(33, "8-11", "B", 10000, 30000), type = "response")
predict(log_model_multi, c(33, "8-11", "B", 10000, 30000), type = "response")
predict(log_model_multi, newdata = c(33, "8-11", "B", 10000, 30000), type = "response")
training_set
predict(log_model_multi, newdata = c(33, "8-11", "B", 10000, 30000), type = "response")
source('~/GitHub/Logistic_Regression/reg_logistic.R', encoding = 'UTF-8', echo=TRUE)
# Obtain significance levels using summary()
summary(log_model_multi)
predict(log_model_multi, newdata = test_set, type = "response")
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
source('~/GitHub/Logistic_Regression/reg_logistic.R', encoding = 'UTF-8', echo=TRUE)
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
# Construir um modelo de regressÃ£o logÃ­stica com ir_cat como variÃ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Vamos ver os parametros do modelo
log_model_cat
# Look at the different categories in ir_cat using table()
table(loan_data$ir_cat)
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
# Build the logistic regression model
predictions_all_small <- predict(log_model_small, newdata = test_set, type = "response")
# Build the logistic regression model
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
head(training_set)
head(test_set)
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
# Construir um modelo de regressÃ£o logÃ­stica com ir_cat como variÃ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Vamos ver os parametros do modelo
log_model_cat
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
# Build the logistic regression model
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_status + loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_cat + ir_cat, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
training_set
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_status + loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_length + ir_cat, family = "binomial", data = training_set)
attach(c(test_set, training_set))
source('~/GitHub/Logistic_Regression/reg_logistic.R', encoding = 'UTF-8', echo=TRUE)
# Look at the predictions range
range(predictions_all_full)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
head(test_set)
# Look at the predictions range
range(predictions_all_full)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_status + loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_length + ir_cat, family = "binomial", data = training_set)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_status + loan_amnt + grade+ home_ownership + annual_inc + age + emp_length + ir_cat, family = "binomial", data = training_set)
training_set
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_length + ir_cat, family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
source('~/GitHub/Logistic_Regression/reg_logistic.R', encoding = 'UTF-8', echo=TRUE)
predictions_all_full
# Look at the predictions range
range(predictions_all_full)
require(rpart)
install.packages("rpart")
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
View(test_set)
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
# Construir um modelo de regressÃƒÂ£o logÃƒ­stica com ir_cat como variÃƒÂ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Vamos ver os parametros do modelo
log_model_cat
View(training_set)
#INICIO FASE DE TESTES E MODELO DE REG LOGÃSTICA E ARVORE DE DECISÃƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
library(stringr)
test_set
str_replace_all(test_set, "11-Aug", "08-11")
test_set <- str_replace_all(test_set, "11-Aug", "08-11")
test_set
test_set
#Upload the data to Rstudio
library(readr)
loan_data <- read_csv("C:\\Users\\User\\Documents\\GitHub\\Logistic_Regression\\loan_data.csv")
#INICIO DE PRE-PROCESSAMENTO
# Save the outlier's index to index_highage
index_highage <- which(loan_data$age > 122)
# Create data set new_data with outlier deleted
loan_data <- loan_data[-index_highage, ]
# Get indices of missing interest rates: na_index
na_index <- which(is.na(loan_data$int_rate))
# Remove observations with missing interest rates: loan_data_delrow_na
loan_data_delrow_na <- loan_data[-na_index, ]
# Make copy of loan_data
loan_data_delcol_na <- loan_data
# Delete interest rate column from loan_data_delcol_na
loan_data_delcol_na$int_rate <- NULL
# Compute the median of int_rate
median_ir <- median(loan_data$int_rate, na.rm = T)
# Make copy of loan_data
loan_data_replace <- loan_data
# Replace missing interest rates with median
loan_data_replace$int_rate[na_index] <- median_ir
# Make the necessary replacements in the coarse classification example below
loan_data$ir_cat <- rep(NA, length(loan_data$int_rate))
loan_data$ir_cat[which(loan_data$int_rate <= 8)] <- "0-8"
loan_data$ir_cat[which(loan_data$int_rate > 8 & loan_data$int_rate <= 11)] <- "8-11"
loan_data$ir_cat[which(loan_data$int_rate > 11 & loan_data$int_rate <= 13.5)] <- "11-13.5"
loan_data$ir_cat[which(loan_data$int_rate > 13.5)] <- "13.5+"
loan_data$ir_cat[which(is.na(loan_data$int_rate))] <- "Missing"
loan_data$ir_cat <- as.factor(loan_data$ir_cat)
loan_data$emp_cat <- rep(NA, length(loan_data$emp_length))
loan_data$emp_cat[which(loan_data$emp_length <= 15)] <- "0-15"
loan_data$emp_cat[which(loan_data$emp_length > 15 & loan_data$emp_length <= 30)] <- "15-30"
loan_data$emp_cat[which(loan_data$emp_length > 30 & loan_data$emp_length <= 45)] <- "30-45"
loan_data$emp_cat[which(loan_data$emp_length > 45)] <- "45+"
loan_data$emp_cat[which(is.na(loan_data$emp_length))] <- "Missing"
loan_data$emp_cat <- as.factor(loan_data$emp_cat)
#DIVISÃƒÂƒO ENTRE DATA SET DE TREINO E DE TESTE
# Set seed of 567
set.seed(567)
# Store row numbers for training set: index_train
index_train <- sample(1:nrow(loan_data), 2/3 * nrow(loan_data))
# Create training set: training_set
training_set <- loan_data[index_train, ]
# Create test set: test_set
test_set <- loan_data[-index_train, ]
test_set
test_set$X1 <- NULL
test_set$X1 <- NULL
test_set
test_set$int_rate <- NULL
test_set$emp_length <- NULL
test_set
training_set
training_set[c("X1","int_rate","emp_length")]
training_set[c("X1","int_rate","emp_length")] <- NULL
training_set
write.csv(training_set, file = "training_set.csv")
write.csv(test_set, file = "test_set.csv")
#INICIO FASE DE TESTES E MODELO DE REG LOGÃƒÂSTICA E ARVORE DE DECISÃƒÂƒO
library(readr)
test_set <- read_csv("test_set.csv")
#INICIO FASE DE TESTES E MODELO DE REG LOGÃƒÂSTICA E ARVORE DE DECISÃƒÂƒO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
View(training_set)
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
# Construir um modelo de regressÃƒÂ£o logÃƒ­stica com ir_cat como variÃƒÂ¡vel preditora
log_model_cat <- glm(loan_status ~ ir_cat,
family = "binomial",
data = training_set
)
# Vamos ver os parametros do modelo
log_model_cat
#QUAL A CHANCE DE DEFAULT PARA ir_cat8-11 ? ir_cat8-11
exp(log_model_cat$coefficients["ir_cat8-11"])
#QUANTO QUE A CHANCE DE DEFAULT AUMENTA SE COMPARARMOS 0-8 (variavel de referencia) COM 8-11
exp(log_model_cat$coefficients["ir_cat8-11"])
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
# Build the logistic regression model
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_length + ir_cat, family = "binomial", data = training_set)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# vamos ver os niveis de significancia dos parametros
summary(log_model_multi)
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# vamos usar a funcao predict para testar nosso modelo no test_set
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
#### vamos usar a funcao predict para testar nosso modelo no test_set
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
#### vamos verificar a variacao do nosso modelo de reg_logistica
range(predictions_all_small)
#### Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
range(predictions_all_full)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),2)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),5)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),5)*100
# Make a binary predictions-vector using a cut-off of 15%
pred_cutoff_15 <- ifelse(predictions_all_full > .15, 1,0)
# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_15)
predictions_all_full
# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_15)
install.packages("rpart")
library("rpart")
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
#ARVORE DE DECISAO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
library("rpart")
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
text(my_tree_two)
plot(my_tree)
text(my_tree)
install.packages('rattle')
library('rattle')
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(my_tree)
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
library('rattle')
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(my_tree)
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class", control = rpart.control(minsplit = 1, minbucket = 1, cp = 0.001 )
)
fancyRpartPlot(my_tree)
fancyRpartPlot(my_tree)
training_set
my_tree <- rpart(loan_status ~ age + grade ,
data = training_set, method = "class",
control = rpart.control(minsplit = 1, minbucket = 1, cp = 0.001))
fancyRpartPlot(my_tree)
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  undersampled_training_set,
control = rpart.control(cp = 0.001))
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  training_set,
control = rpart.control(cp = 0.001))
fancyRpartPlot(tree_undersample)
plot(tree_undersample, uniform= T)
library(rpart)
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  training_set,
control = rpart.control(cp = 0.001))
plot(tree_undersample, uniform= T)
tree_prior <- rpart(loan_status ~ ., method = "class",                    data = training_set, parms = list(prior=c(0.7,0.3)), control = rpart.control(cp = 0.001))
# Plot the decision tree
plot(tree_prior, uniform = T)
# Add labels to the decision tree
text(tree_prior)
# Plot the decision tree
plotcp(tree_prior, uniform = T)
# Add labels to the decision tree
princp(tree_prior)
# Add labels to the decision tree
printcp(tree_prior)
# Add labels to the decision tree
prp(tree_prior)
library(rpart)
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# Plot the decision tree
plot(tree_prior, uniform = T)
# Add labels to the decision tree
text(tree_prior)
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# adicionaremos o texto na arvore
text(tree_prior)
# adicionaremos o texto na arvore
text(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
# Create tree_min
tree_min <- tree_prior$cptable[index, "CP"]
#  Prune the tree using tree_min
ptree_prior <- prune(tree_prior, cp = tree_min)
# Use prp() to plot the pruned tree
prp(ptree_prior)
confmat_prior <- table(test_set$loan_status, pred_prior)
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
pred_prior
confmat_prior
acc_prior
# Load the pROC-package
library(pROC)
install.packages("pROC")
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
# Load the pROC-package
library(pROC)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_all_full)
# Draw all ROCs on one plot
plot(ROC_logit)
# Compute the AUCs
auc(ROC_logit)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
ROC_prior <- roc(test_set$loan_status, predictions_prior)
source('~/GitHub/Logistic_Regression/arvore_de_decisao.R', echo=TRUE)
ROC_prior <- roc(test_set$loan_status, pred_prior)
lines(ROC_prior, col="blue")
pred_prior
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 0.8)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
# Obtain the actual default status for the accepted loans
accepted_status_prior_80 <-  test_set$loan_status[bin_pred_prior_80 == 0]
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
ROC_prior <- roc(test_set$loan_status, pred_prior)
ROC_prior <- roc(test_set$loan_status, prob_default_prior)
lines(ROC_prior, col="blue")
plot(ROC_prior, col="blue")
auc(ROC_prior)
