log_model_cat
#QUAL A CHANCE DE DEFAULT PARA ir_cat8-11 ? ir_cat8-11
exp(log_model_cat$coefficients["ir_cat8-11"])
#QUANTO QUE A CHANCE DE DEFAULT AUMENTA SE COMPARARMOS 0-8 (variavel de referencia) COM 8-11
exp(log_model_cat$coefficients["ir_cat8-11"])
# Build the logistic regression model
log_model_multi <- glm(loan_status ~ age + ir_cat + grade + loan_amnt + annual_inc, family = "binomial", data = training_set)
# Obtain significance levels using summary()
summary(log_model_multi)
# Build the logistic regression model
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ loan_amnt + grade
+ home_ownership + annual_inc +
age + emp_length + ir_cat, family = "binomial", data = training_set)
# Build the logistic regression model
log_model_full <- glm(loan_status ~ ., family = "binomial", data = training_set)
# Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# vamos ver os niveis de significancia dos parametros
summary(log_model_multi)
# Look at the range of the object "predictions_all_small"
range(predictions_all_small)
# vamos usar a funcao predict para testar nosso modelo no test_set
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
#### vamos usar a funcao predict para testar nosso modelo no test_set
predictions_all_small <- predict(log_model_multi, newdata = test_set, type = "response")
#### vamos verificar a variacao do nosso modelo de reg_logistica
range(predictions_all_small)
#### Make PD-predictions for all test set elements using the the full logistic regression model
predictions_all_full <- predict(log_model_full, newdata = test_set, type = "response")
# Look at the predictions range
range(predictions_all_full)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
range(predictions_all_full)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),2)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),5)
# vamos verificar novamente a variacao de probabilidade do nosso modelo
round(range(predictions_all_full),5)*100
# Make a binary predictions-vector using a cut-off of 15%
pred_cutoff_15 <- ifelse(predictions_all_full > .15, 1,0)
# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_15)
predictions_all_full
# Construct a confusion matrix
table(test_set$loan_status, pred_cutoff_15)
install.packages("rpart")
library("rpart")
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
#ARVORE DE DECISAO
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
library("rpart")
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
text(my_tree_two)
plot(my_tree)
text(my_tree)
install.packages('rattle')
library('rattle')
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(my_tree)
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class")
library('rattle')
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(my_tree)
my_tree <- rpart(loan_status ~ ., data = training_set, method = "class", control = rpart.control(minsplit = 1, minbucket = 1, cp = 0.001 )
)
fancyRpartPlot(my_tree)
fancyRpartPlot(my_tree)
training_set
my_tree <- rpart(loan_status ~ age + grade ,
data = training_set, method = "class",
control = rpart.control(minsplit = 1, minbucket = 1, cp = 0.001))
fancyRpartPlot(my_tree)
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  undersampled_training_set,
control = rpart.control(cp = 0.001))
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  training_set,
control = rpart.control(cp = 0.001))
fancyRpartPlot(tree_undersample)
plot(tree_undersample, uniform= T)
library(rpart)
tree_undersample <- rpart(loan_status ~ ., method = "class",
data =  training_set,
control = rpart.control(cp = 0.001))
plot(tree_undersample, uniform= T)
tree_prior <- rpart(loan_status ~ ., method = "class",                    data = training_set, parms = list(prior=c(0.7,0.3)), control = rpart.control(cp = 0.001))
# Plot the decision tree
plot(tree_prior, uniform = T)
# Add labels to the decision tree
text(tree_prior)
# Plot the decision tree
plotcp(tree_prior, uniform = T)
# Add labels to the decision tree
princp(tree_prior)
# Add labels to the decision tree
printcp(tree_prior)
# Add labels to the decision tree
prp(tree_prior)
library(rpart)
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# Plot the decision tree
plot(tree_prior, uniform = T)
# Add labels to the decision tree
text(tree_prior)
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# adicionaremos o texto na arvore
text(tree_prior)
# adicionaremos o texto na arvore
text(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
# Create tree_min
tree_min <- tree_prior$cptable[index, "CP"]
#  Prune the tree using tree_min
ptree_prior <- prune(tree_prior, cp = tree_min)
# Use prp() to plot the pruned tree
prp(ptree_prior)
confmat_prior <- table(test_set$loan_status, pred_prior)
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
pred_prior
confmat_prior
acc_prior
# Load the pROC-package
library(pROC)
install.packages("pROC")
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
# Load the pROC-package
library(pROC)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_logit)
# Construct the objects containing ROC-information
ROC_logit <- roc(test_set$loan_status, predictions_all_full)
# Draw all ROCs on one plot
plot(ROC_logit)
# Compute the AUCs
auc(ROC_logit)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
ROC_prior <- roc(test_set$loan_status, predictions_prior)
source('~/GitHub/Logistic_Regression/arvore_de_decisao.R', echo=TRUE)
ROC_prior <- roc(test_set$loan_status, pred_prior)
lines(ROC_prior, col="blue")
pred_prior
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 0.8)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
# Obtain the actual default status for the accepted loans
accepted_status_prior_80 <-  test_set$loan_status[bin_pred_prior_80 == 0]
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
ROC_prior <- roc(test_set$loan_status, pred_prior)
ROC_prior <- roc(test_set$loan_status, prob_default_prior)
lines(ROC_prior, col="blue")
plot(ROC_prior, col="blue")
auc(ROC_prior)
library(rpart.plot)
#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
rpart.plot(tree_prior)
rpart.plot(tree_min)
#Precisamos dar restart nos datasets
library(readr)
test_set <- read_csv("test_set.csv")
training_set <- read_csv("training_set.csv")
attach(c(test_set, training_set))
test_set$X1 <- NULL
training_set$X1 <- NULL
#instalar a biblioteca que contem o modelo de arvore de decisao
#install.packages("rpart")
library(rpart)
#construiremos o modelo de arvore de decisao
tree_prior <- rpart(loan_status ~ ., method = "class",
data = training_set, parms = list(prior=c(0.7,0.3)),
control = rpart.control(cp = 0.001))
# plotaremos a arvore
plot(tree_prior, uniform = T)
# adicionaremos o texto na arvore
text(tree_prior)
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
# Create tree_min
<- tree_prior$cptable[index, "CP"]
#  Prune the tree using tree_min
ptree_prior <- prune(tree_prior, cp = tree_min)
# Use prp() to plot the pruned tree
prp(ptree_prior)
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_prior
acc_prior <- sum(diag(confmat_prior)) / nrow(test_set)
acc_prior
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 0.8)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
# Obtain the actual default status for the accepted loans
accepted_status_prior_80 <-  test_set$loan_status[bin_pred_prior_80 == 0]
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
ROC_prior <- roc(test_set$loan_status, prob_default_prior)
plot(ROC_prior, col="blue")
auc(ROC_prior)
library(rpart.plot)
rpart.plot(tree_min)
rpart.plot(as.rpart(tree_min))
str(tree_min)
str(tree_prior)
tree_min
str(ptree_prior)
rpart.plot(ptree_prior)
training_set
novos_dados <- data.frame(
loan_amnt = 10000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = 8-11 ,
emp_cat = 0-15 )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 10000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior, novos_dados, type = "response")
class
predict(ptree_prior, novos_dados, type = "class")
novos_dados
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 1000000,
grade = "B" ,
home_ownership = "RENT" ,
annual_inc = 10000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = "8-11" ,
emp_cat = "0-15" )
predict(ptree_prior, novos_dados, type = "class")
novos_dados <- data.frame(
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = as.factor("8-11") ,
emp_cat = as.factor("0-15"))
predict(ptree_prior, novos_dados, type = "class")
predict(ptree_prior  , newdata = test_set,  type = "class")
answer = predict(ptree_prior, novos_dados, type = "class")
answer = predict(ptree_prior, novos_dados, type = "class"))
answer
answer
answer
answer
novos_dados <- data.frame(loan_status = 1,
loan_amnt = 100,
grade = "A" ,
home_ownership = "RENT" ,
annual_inc = 1000000,
age = 30,
ir_cat = as.factor("8-11") ,
emp_cat = as.factor("0-15"))
answer = predict(ptree_prior, novos_dados, type = "class")
answer
ir_cat = as.factor(c("8-11")) ,
novos_dados <- data.frame(loan_status = c(1),
loan_amnt = c(100),
grade = c("A") ,
home_ownership = c("RENT") ,
annual_inc = c(1000000),
age = c(30),
ir_cat = as.factor(c("8-11")) ,
emp_cat = as.factor(c("0-15")))
answer = predict(ptree_prior, novos_dados, type = "class")
answer
answer = predict(tree_prior, novos_dados, type = "class")
answer
answer = predict(tree_prior, newdata = novos_dados, type = "class")
answer
pred_prior <- predict(ptree_prior  , newdata = test_set,  type = "class")
confmat_prior <- table(test_set$loan_status, pred_prior)
confmat_prior
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(0),
loan_amnt = c(100),
grade = c("A") ,
home_ownership = c("RENT") ,
annual_inc = c(1000000),
age = c(30),
ir_cat = as.factor(c("8-11")) ,
emp_cat = as.factor(c("0-15")))
answer = predict(tree_prior, newdata = novos_dados, type = "class")
table(novos_dados$loan_status, answer)
answer
View(test_set)
novos_dados
colnames(novos_dados)
identical(colnames(novos_dados), colnames(test_set))
colnames(test_set)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
answer = predict(tree_prior, newdata = novos_dados, type = "class")
table(novos_dados$loan_status, answer)
answer
resposta
resposta
resposta = predict(tree_prior, newdata = novos_dados, type = "class")
resposta
table(novos_dados$loan_status, answer)
source('~/GitHub/Logistic_Regression/regressao_logistica.R', echo=TRUE)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(predictions_all_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(0,1),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
novos_dados <- data.frame(loan_status = c(),
loan_amnt = c(100,200),
grade = c("A", "C") ,
home_ownership = c("RENT", "RENT") ,
annual_inc = c(1000000,5000),
age = c(30,20),
ir_cat = as.factor(c("8-11", "0-8")) ,
emp_cat = as.factor(c("0-15","0-15")))
resposta = predict(log_model_full, newdata = novos_dados, type = "response")
table(novos_dados$loan_status, answer)
table(novos_dados$loan_status, resposta)
predict(log_model_full, newdata = novos_dados, type = "response")
# Plot the cross-validated error rate as a function of the complexity parameter
plotcp(tree_prior)
# Create an index for of the row with the minimum xerror
index <- which.min(tree_prior$cptable[ , "xerror"])
index
# Use printcp() to identify for which complexity parameter the cross-validated error rate is minimized.
printcp(tree_prior)
tree_prior
tree_prior$cptable
tree_prior$cptable[ , "xerror"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
tree_prior$cptable[index, "CP"]
prune(tree_prior, cp = tree_min)
# E agora vamos ver a nossa arvore usando prp, que faz uma arvore mais bonita
prp(ptree_prior)
confmat_prior
nrow(test_set
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
nrow(test_set)
acc_prior
predict(ptree_prior, newdata = test_set)[ ,2]
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)
predict(ptree_prior, newdata = test_set)
# Make predictions for the probability of default using the pruned tree and the test set.
prob_default_prior <- predict(ptree_prior, newdata = test_set)[,2]
[,2]
predict(ptree_prior, newdata = test_set)[,2]
quantile(prob_default_prior, 0.8)
ifelse(prob_default_prior > cutoff_prior, 1, 0)
test_set$loan_status[bin_pred_prior_80 == 0]
prob_default_prior
quantile(prob_default_prior, 0.8)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 0.1)
quantile(prob_default_prior, 1)
quantile(prob_default_prior, 1)
mean(prob_default_prior)
prob_default_prior
mean(prob_default_prior[1])
prob_default_prior[1]
prob_default_prior[1]
prob_default_prior[1]
mean(prob_default_prior)
# Obtain the binary predictions.
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, 1)
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
cutoff_prior
prob_default_prior
#Aqui, selecionaremos as probabilidades de default do nosso modelo
prob_default_prior <- predict(ptree_prior, newdata = test_set)[ ,2]
# Obtain the cutoff for acceptance rate 80%
cutoff_prior <- quantile(prob_default_prior, .2)
cutoff_prior
cutoff_prior
# Vamos transformar o nosso data_set em 1 e 0
bin_pred_prior_80 <- ifelse(prob_default_prior > cutoff_prior, 1, 0)
bin_pred_prior_80
accepted_status_prior_80
# Obtain the bad rate for the accepted loans
sum(accepted_status_prior_80) / length(accepted_status_prior_80)
